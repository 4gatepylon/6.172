# Source - Multicore Programming
https://www.youtube.com/watch?v=dx98pqJvZVk

# Notes
## Cache Coherence
Recall the MSI Stack and the fact that variants (i.e. MOESI) exist: "modified, shared, invalid."

If your code is not independent (i.e. where it reads and writes) then each time you write to your own
cache the other caches will need to be kept coherent, which may cause issues.

Normally caching is done by cache lines, which are aligned in a mysterious way. That is to say, if you
fetch an address, it is not necessary the start, end, or any other constant reference point with respect
to the locations of the cache line.

If multiple processors write, each needs to let each other know that this happened, and it can lead to quadratic behavior.

## Concurrency Platforms
From lower to higher level.

P_threads: basically just threads in linux. There is also the WinAPI threads. The idea here is to abstract the behavior of multiple
processors. It's hard to use and we won't use it. Basically you create threads that run functions passed in by function pointers.
These functions should return statuses and the thread will return its own status.

There is also "Threading Building Blocks" (TBB) which are an Intel-produced tool for C++. You create a class with an execute function
that represents a "task." There are also other abstractions for other types of multithreading. It's a library.

There is also OpenMP which alows you to insert #pragmas for the preprocessor to modify your code into something threadable. It's nicer
than the other two since it's much more modular, minimalistic, easy to use, etcetera. P_threads, as you well know, completely change the
look of a program, for example. We won't be using OpenMP, at least yet, I think.

Interestingly, OpenMP runs on Fortran and C++. It also gives you various directives like for mutexes, reduction, (data aggregation),
scheduling, etcetera.

We will use Cilk from MIT. They seem to love Cilk.

NOTE: Cilk and the higher level threading APIs tend to do automatic load balancing (etc) for you, while the lower ones like P_thread might
not.

Cilk is very nice because it can help you prove theoritcal bounds on your algorithms. It also has a data race detector which is 
super helpful.

It also has a library to help you parallelize with global variables. They call this a hyperobject library.

# Cilk
Cilk commands do not force or comand parallel execution; they simply allow it. With P_threads it can be easy to make code that MUST be
parallel (or deadlock or whatever). In Cilk, THE SERIAL PROGRAM SHOULD BEHAVE THE SAME AS THE PARALLEL VERSION. The serial version is a "legal interpretation."

They give us the example of macros for reducers. The reducer deals with determinacy races for you in various cases. Recall the example of the sum data race condition that is fixed by using a reducer for the global sum variable instead.

You can usually create reducers for monoids (associative, binary, has identity). Cilk has various reducers and you can write your own as well.