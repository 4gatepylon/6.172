# Source - Analysis of Multithreaded Algorithms
https://www.youtube.com/watch?v=6I26_r1BKd8

# Notes
## Master Method (Review)
There are 3 cases. Basically if you have T(n) = aT(n / b) + f(n) and you have it such that f(n) is polynomially larger
than n^(log_b(a)) you get the f(n) as the runtime (because it's roughly a geometrically decreasing sequence). If you have
n^(log_b(a)) as being polynomially larger then you get n^(log_b(a)) as your runtime. Otherwise, ONLY if f(n) is the same within
a log factor LARGER we have it such that for n^(log_b(a))lg^k(n) = O(f(n)), the runtime will be n^(log_b(a))lg^(k+1)(n). We do
not really know in other cases.

The way to find this is to sum over the rows. Note that the first row will cost f(n), then (a)f(n/b), then (a^2)f(n/(b^2)) and so on
to eventually a^(log_b(n))f(1) = n^(log_b(a)) assuming f(1) = O(1). The three cases above correspond to geometrically decreasing, increasing,
or arithmetically increasing/decreasing.

Maybe prove this more rigorously? You can do OK just by plugging into the total cost equation and using the definition of big O
(i.e. the total cost is the sum from i = 0 to i = log_b(a) of (a^i)f(n/(b^i))).

## Akra Bazzi
This is a more general form of the master theorem that you can use in harder problems. We don't go into it because it's
more complicated. You can find it here: https://en.wikipedia.org/wiki/Akra%E2%80%93Bazzi_method.

## Analysis of parallel loops
There is no loop primitive. It's usually splitting it into two halves. Recall the example with the matrix transpose.

### Transpose with outer loop parallelized
Also note that "span" and "work" are for an algorithm, not for a problem. We all know that if you had O(N^2) processors you
could execute transpose in O(1) time (assuming no overwriting of old memory), but for the algorithm they do where they split
the vertical direction into halves, it's different: since they split into two there is a binary tree with the leaves being
serial code to copy an entire row: therefore, the span is lgN + N = O(N) while the work was obviously O(N^2) to begin with.

Note how they split not that smartly; i.e. it didn't load balance ideally because the first processors got the small row-lengths,
while the later ones got the long row-lengths.

### Transpose with both loops parallelized
The inner loop now becomes anther nested set of trees and the the leaves are the singleton swaps, meaning that the program has lgN span
instead of N + lgN span. Thus, our parallelism becomes O(N^2/lgN). It might have too much overhead for our need though. Recall parallel
slackness: we only want to be sufficiently above the number of processors. If the number of processors is low, we don't need even
more parallelism since we cannot really use it well.

### Overheads
#### Loop Grain Size Example: Vector Add
The cilk system has a "#pragma grainsize G" which you can use on cilk_for to increase the coarseness of the silk_spawn call base case.
If you don't specify the cilk runtime tries to be clever and pick the right amount.

You can think of divide and conquer vector addition as a tree with the array chunked into consecutive slices as the leaves (i.e. those
chunks are the leaves). If they have size G (for grain size) and the array has N elements and we take I to do an add (for instruction)
then we would have around N/G leaves and thus N/G - 1 non-leaves in the parallel recursion tree, and thus approximately
lg(N/G) + G * I span (since we need to execute G instructions on the leaf sequentially after a path down) and N * I + (N/G - 1) * S work where S is the recursive work (think "spawn" and "sync" work). Thus we want to lower work by increasing G, but avoid increasing G too much
because then the span would be big. Note that the G * I is the dominant term in the span equation.

Note that we ignore order for the divide and conquer vector add (i.e. caching).

You could instead have an outer loop that spawned sub-workers on each G-chunk. This would have work O(N) while it would have span
N/G + G (since you need to spawn off N/G processes, but G is the length of each chunk). This might be better (also has less syncs
so it should have less overhead). They give an example.

What if you had P processors and split evenly? Then N/G = P and G = N/P. You can plug into the stuff from above for that.

## Heuristics
It's usually better to use cilk_for instead of cilk_spawn unless you have a specifically smarter technique.

Generally it's better to parallelize the outer loop rather than the inner loop.

## Matrix Multiplication Example
Might want to learn Strassen. It's  good for parallelization and used divide and conquer. Remember the efficient method
for multiplication (Karatsuba)? It's like that.

How do you index inside a sub-matrix (row times total matrix width plus column). Where does that come from (the cross).

Probably you should take this home to analyse the parallelism.

Recall the clever macro trick! (Use "##" to basically remove the whitespace so you can have "n_" and then append the NAME of the matrix).