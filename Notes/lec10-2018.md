# Source - Measurement and Timing
https://www.youtube.com/watch?v=LvX3g45ynu8

# Notes
## Example: Measuring Merge Sort on Laptop
I thought it may have been cache, but it wasn't because it went back down. It also wasn't something in the background or
autoscaling of any kind. It was clock frequency!

There can be a million things that affect your timing. Example from the lecture (that went up and down in decreasing
length intervals) turned out to be clock frequency! The computer would heat up so it would lower clock frequency, then it would
cool down so it would increase the clock frequency. The larger jobs heated it up more, so they had shorter periods of high
frequency. It may have also been conserving battery.

## Non-Constant Clock Frequency
Power is proportional to CV^2f (for clock frequency f, voltage supply V, and dynamic capacitance C). Thus, by lowering the frequency the power can be lowered. Alternatively, the voltage can be lowered. They dynamic capacitance is roughly the area of the circuit times
the number of bits that are moving.

This modulation is called DVFS.

So How Can We Measure Performance Well With Shit Like DVFS? For DVFS you can overclock (like when gaming) to 
keep the frequency high. But what else?

## Quiescing Your System
Recall the example of the Japanese automobile manufacturing leader who increasing quality: Genichi Taguchi. The idea is
too tackle unreliability before tackling quality. By making you sure can reproduce the exact same thing every time, then you
can easily measure when you are improving. Otherwise you don't even know if you are in the noise!

### Sources of Noise
- DVFS (the clock frequency modulation from before)
- TurboBoost (another form of clock frequency modulation in which if only a single core is running it gets scaled up).
- Hyperthreading (like multi-threading, but you use the same functional unit with two sets of registers, memory, etcetera) Hyperthreading gives you around 1.2 processors instead of 2.
- Thread placement (where the work is put on the cores)
- Runtime scheduler
- Multitenancy? I think this means when many people are using the same computer.
- Network Traffic
- System interrupts (i.e. IO for the screen, mouse, keyboard, etcetera; recall the example of the graduate student moving the mouse around)
- Code and data alignment
- Daemons and background jobs

### Fixes
They noticed that the difference can be a variance from 0.7% to 25%, so it's a big thing!

- Don't run on core 0! Usually the OS runs interrupt handlers and other such things on core 0.
- Make sure no other jobs are running.
- Don't do IO. Don't move the mouse (etc).
- Don't connect to the network.
- Turn off DVFGS and TurboBoost.
- Turn off Hyperthreading.
- Use a tool like `taskset` to set workers (i.e. pthreads or cilk workers) to specific cores.
- Shut down daemons and other such jobs.

There are more things to do, but `awsrun` does most of it for us.

You can't absolutely fix randomness since at the end of the day there is cosmic radiation and if it flips a bit, error correction needs
to be done.

### Code Alignment
Changing the code alignment can create big variance! Even just changing the order in which the `.o` files show up in the linker
command can have as big a difference as switching from `-O2` to `-O3`.

Luckily, now compilers give you the option to have functions always start at the first line of a cacheline. Alternatively (or additionally) you can ask to have (llvm basic) blocks start at the beginning of cache lines. It's likely the compiler is doing this by default, but you
can try and see.

You can also align all blocks that have no fall-through predecessors (the ones that usually create the problems). It's not clear what
these are.

Note that unaligned code can sometimes be faster, but less consistent.

Even a program's name can change its name since that gets put in an environment variable which gets put on the call stack!

## Tools for Measuring
Prof. Leiserson thought of five classes of tools
- Timing exernally (use the operating system time, say, in a bash script)
- Timing internally (put timing calls into the program)
- Interrupting the program (like gdb) to check the time
- Using hardware and/or OS support  by using program counters or other such things (like perf)
- Simulations (like valgrind)

### External
Timing externally with the `time` command usually measures elapsed time, system time, and user time. Elapsed time is the change in time from the beginning to the end (wall clock), while user time is the sum of the time spent working on your stuff (note that for multiple processors
the times are summed across processors) and system time is the time the kernel took to do scheduling and other such things.

### Internal
Timing internally, he strongly recommends to use `clock_gettime(CLOCK_MONOTONIC, ...)`. The monotonic option is important because it
guarantees that the timer does not run backwards. Some of the other timers query a national standards time periodically and that might
mess with your timings. He does not recommend that we use a cycle counter since the cycle time can change (and may have different counts
on different cores, may run backwards, etcetera). Moreover, he does not recommend that we use `gettimeofday()` since it also can run
backwards and other such nonsense (it gives you microsecond precision even though it is not microsecond accurate).

For atomicity reasons `clock_gettime` needs to read (at least) twice to avoid atomicity problems (with the time updating). It takes around
80ns.

### Interrupts
This is how google perf does it. Basically, they interrupt your program around 100 times per second and look at the call-stack to see what
function the program is in. Note that this sampling may not be sufficient, meaning that google perf may not be perfect. However, these are
great starter tools (i.e. Facebook and other such companies have used these things).

### Hardware Counters
There is a library called libpfm4 which allows you to count per-process for various different program counters. Do not count more than 4-5
things at a time or else you may change program performance! There are many esoteric counters and few counters are well-documented. Note
that these can also be tricky. Recall the cache miss example (the cache miss was not being counted due to some form of "pre-fetching").

### Simulation
Simulation is very accurate and lets you focus on some very specific things (like cache-misses). The only problem is that it is slow.

Final thought: NEVER TAKE JUST ONE MEASUREMENT. Take multiple numbers and triangulate them. Understand why there are discrepancies
if there are discrepancies! And never trust a number unless you have a model for it!

## Performance Modeling
Measuring the minimum is a good measure for noise-rejection (because noise us almost always positive).

### Means
For other purposes arithmetic mean, median, and maximum are all often used.

Never use arithmetic mean for a bunch of ratios! The mean of the ratio is not the ratio of the mean for example. Also doing the inverse
ratio does not yield the inverse ratio. For ratios you want to use the geometric mean. It's like taking the average of the logs and
converting back (i.e. the n-th root of the product). The geometric mean of the ratios os the ratio of the geometric means.

When looking at rates you also want to avoid the arithmetic mean too. There, you may want to use the harmonic mean to keep
the nice mathematical properties we expect of a mean.

### Strategies For Measuring With Noise
It may be hard to use means. In that case you could run many trials and just note who wins. Then you could look at the probability
that A beats B given the assumption that B beats A. You can then use p-values and other such statistics. Also, it's good (I think)
because usually the noise will be correlated across nearby runs.

You can also fit your timings to a model (i.e. least squares with two variables: instruction time and cache-time, or something else).
Adding basis functions can help you fit the model fit, but it can overfit.